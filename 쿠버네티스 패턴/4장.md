# 4장 정상상태 점검
- 정상상태 점검(Health Probe) 패턴은 애플리케이션이 쿠버네티스와 정상상태 여부를 통신하는 방법에 관한 패턴
- 완전 자동화에 도달하기 위해서는 쿠버네티스가 클라우드 네이티브 애플리케이션의 실행 여부와 요청 처리 준비 상태 여부를 감지할 수 있어야 함
- 애플리케이션은 상태를 유추 가능해야하며, 이러한 관측은 파드의 수명주기 관리에 영향을 줌

## 문제
- 쿠버네티스는 컨테이너 프로세스 상태를 주기적으로 확인하고 문제가 감지되면 컨테이너를 재시작
- 하지만, **실제 상황에서 프로세스 상태 확인은 애플리케이션 정상상태를 결정하기에 충분하지 않음**
  - 애플리케어션에 hang이 걸리더라도 프로세스는 여전히 실행 중(ex. 자바에서 `OutofMemoryError` 발생 시 여전히 JVM 프로세스는 실행중)
  - 애플리케이션이 무한루프 또는 교착 상태, 특정 thrasing(캐시, 힙, 프로세스)로 인해 동작을 안할 수 있음
- 이런 상황을 감지하기 위해서는 애플리케이션의 정상상태를 체크할 수 있는 신뢰할 만한 방법 필요

## 해결책
- 소프트웨어 업계에서 버그 없는 코드를 작성하는 것은 불가능 (+ 분산 애플리케이션은 장애가 일어날 확률 훨씬 높음)
- 장해를 피하는 것이 아닌, **오류를 감지하고 복구**하는 쪽으로 생각해야함
- 장애에 대한 정의는 천차 만별이므로, 수많은 유형의 장애별로 그에 맞는 장애 조치 필요

### 프로세스 정상상태 확인 (process health check)
- 프로세스 정상상태 확인은 큐블릿(kubelet)이 컨테이너 프로세스에 대해 지속적으로 수행하는 가장 간단한 정상상태 확인
- 컨테이너 프로세스가 실행 중이 아니라면, 점검(probing)은 다시 시작됨
- 때문에 또다른 정상상태 확인 없이도, 애플리케이션은 이러한 일반적인 확인 단계로 좀 더 견고해짐
- 그러나 대부분의 경우 이것만으로는 충분하지 않아, 다른 유형의 정상상태 확인 필요

### 라이브니스 점검 (Liveness probe)
- 애플리케이션이 교착 상태에 빠지면, health check으로는 여전히 정상으로 간주
- 라이브니스 점검이란 큐블릿 에이전트가 정기적으로 검사를 수행해 컨테이너가 여전히 정상상태인지 확인하는 과정
- 일부 장애는 애플리케이션 워치독(watchdog)이 장애 보고를 못할 수도 있으므로, 애플리케이션 **외부에서 정상상태 확인을 수행하는 것이 중요**
- 장애가 감지되는 경우 컨테이너가 재시작된다는 점에서 라이브니스 점검은 프로세스 정상상태 확인과 유사
- 하지만, 정상상태 확인 시 조금 더 융통성 있는 방법을 사용함
  - HTTP 점검은 컨테이너 IP 주소에 대해 HTTP GET 요청을 수행하여 200-399 사이의 응답코드 기대
  - TCP 소켓 점검은 성공적인 TCP 연결 가정
  - Exec 점검은 컨테이너 커널 네임스페이스에서 임의의 명령을 실행하고 성공적인 종료 코드(0) 기대

#### HTTP 기반 라이브니스 점검 예시
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: pod-with-liveness-check
spec:
  containers:
  - image: k8spatterns/random-generator:1.0
    name: random-generator
    env:
    - name: DELAY_STARTUP
      value: "20"
    ports:
    - containerPort: 8080
    protocol: TCP
    livenessProbe:
      httpGet:     # 정상상태 확인 종단점으로 HTTP 점검
        path: /actuator/health
        port: 8080
      initialDelaySeconds: 30     # 애플리케이션에 준비 시간을 주기 위해 첫번째 점검을 수행하기 전 30초 기다림
``` 

#### ⚠️ 근본적인 문제 해결 없이 컨테이너를 재시작하므로 재시작이 소용없는 경우, 정상상태 확인 실패는 아무런 도움이 되지 않음

### 레디니스 점검 (readiness probe)
- 컨테이너를 재시작해도 도움이 안되는 경우
   - 컨테이너가 시작 중이고 요청을 처리할 준비가 안되어있는 경우
   - 컨테이너가 과부하에 걸려 또다른 부하로부터 보호받아야 하는 경우
- 레디니스 점검 수행 방법은 라이브니스 점검과 동일하지만, **장애 조치가 다름** (컨테이너 재시작 X)
- 레디니스 점검에 실패 시 컨테이너는 Service Endpoint에서 제거되고 새로운 트래픽 수신 X
- 레디니스 점검은 컨테이너가 **서비스 요청을 받기 전에 준비할 수 있는 시간을 갖도록 컨테이너가 준비되는 시점에 신호**를 보냄
- 라이브니스 점검처럼 주기적으로 실행되므로 이후 단계의 트래픽으로부터 서비스를 보호하는데 유용

```yaml
apiVersion: v1
kind: Pod
metadata:
   name: pod-with-readiness-check
spec:
   containers:
   - image: k8spatterns/random-generator:1.0
   name: random-generator
   readinessProbe:
     exec: # 애플리케이션이 서비스 요청 처리 준비가 되었음을 나타내는 파일이 존재하는지 확인. 존재하지 않을 경우 에러반환하여 점검 실패
       command: [ "stat", "/var/run/random-generator-ready" ]
```

#### 💡 언제 애플리케이션이 작업 수행 준비가 되었는지를 판별하고, 언제 그대로 둬야할지 결정하는 것은 정상상태 확인 코드를 어떻게 구현하는지에 따라 다름
- 프로세스 정상상태 확인과 라이브니스 점검은 컨테이너를 재시작해 장애를 복구
- 레디니스 점검은 애플리케이션에 준비할 시간을 주고 스스로 복구되기를 기다림
- 대부분의 경우, 라이브니스와 레디니스 점검은 동일한 체크를 수행
   - 레디니스 점검이 있으면 컨테이너에게는 시작할 수 있는 시간이 주어짐
   - 레디니스 점검을 통과해야만 디플로이먼트가 성공한 것으로 간주 
- Springactuator, Wild-Fly Swarm, Karaf, MicroProfile spec 등의 애플리케이션 프레임워크가 정상상태 점검을 위한 구현 제공

## 정리
- 완전 자동화를 위해, 정상상태를 읽고, 해석하고, 필요시 조치활동에 대한 수단을 제공함으로써 관찰해야함
- 애플리케이션이 정상상태에 대해 더 많은 가시성을 제공할 수 있는 방법은 더 있음 → **로깅**

#### 로깅
- 컨테이너가 중요한 이벤트를 시스템 밖으로 보내고, 시스템 에러를 로그로 남기고, 추후 분석을 위해 중앙에서 이 로그들을 수집하는 것이 좋음
- **장애에 대한 사후 분석 및 눈에 띄지 않는 오류에 대한 탐지 가능**
- 표준 스트림에 로그를 남기는 것 이외에도 컨테이너가 종료되는 이유를 `/dev/termination-log`에 로그로 남기는 것이 좋음

#### 컨테이너 관측성 옵션
<img width="465" alt="스크린샷 2025-01-17 오후 5 57 28" src="https://github.com/user-attachments/assets/6f06a22a-f8b2-4fe7-954e-9436f8004050" />

- 컨테이너는 블랙박스처럼 취급되어 애플리케이션을 패키징하고 실행하는 통합된 방법 제공
- 컨테이너화된 애플리케이션은 최소한 🚨 **정상상태 확인을 위한 API 제공해야함**
- 잘 동작하는 애플리케이션이라 하더라도 관리 플랫폼이 OpenTracing이나 Prometheus 같은 트레이싱 및 메트릭 수집 라이브러리와 통합하여 컨테이너화된 애플리케이션 상태를 관찰할 수 있도록 또다른 수단 제공해야함
