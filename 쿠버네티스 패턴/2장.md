# 2장 예측 범위 내의 요구사항
- 공유 클라우드 환경에서 애플리케이션 배포 및 관리를 성공적으로 수행하려면 애플리케이션 자원 요구사항과 런타임 의존성을 명확히 식별하고 정의해야 함
- **예측 범위 내의 요구사항 패턴**은 물리적으로 필요한 런타임 환경 의존성이나 자원 요구사항과는 상관없이, 애플리케이션 요구사항을 선언하는 방법에 관한 것으로, 쿠버네티스가 클러스터 내에서 애플리케이션에 적합한 노드를 찾기 위해 반드시 필요함

## 문제
### 쿠버네티스는 다른 프로그래밍 언어로 작성된 애플리케이션도 관리 → 언어에 따라 각기 요구사항이 다름
- 컴파일 언어: 빠르게 실행되며, 다른 언어에 비해 메모리 소모가 낮음
- 인터프리터 언어: 실행 중 기계어 코드 실행
- JIT(just-in-time) 런타임: 프로그램을 실제 실행하는 시점에 기계어로 번역(매번 실행 시점에 X, 캐싱). 컴파일+인터프리터 방식
#### 💡 언어의 종류보다는 도메인이나, 애플리케이션의 비즈니스 로직 혹은 실제 세부적인 구현사항이 훨씬 더 중요함

### 컨테이너가 최적의 기능을 수행하는데 필요한 자원량을 예측하기 어려움
- 개발자가 테스트를 수행한 후에야 비로소 서비스 구현을 위한 자원 필요량을 알 수 있음
  - 고정된 CPU, 메모리 소비 프로파일을 가진 서비스
  - 스파이크를 치는 서비스
  - 영구적인 스토리지가 필요한 서비스
  - 호스트 서버에 고정된 특정 포트 번호를 사용해야 작동하는 레거시 서비스
- 모든 애플리케이션 특성을 정의하고 이를 관리 플랫폼으로 전달하는 것이 클라우드 네이티브 애플리케이션의 기본 전제 조건
- 자원 요구사항 외에도 애플리케이션 런타임은 데이터 스토리지(PV) 또는 애플리케이션 설정(Configmap, Secret) 같은 플랫폼 관리 기능도 필요

## 해결책


### 모든 런타임 의존성 정의
#### 💡 모든 런타임 의존성이 정의되고 자원 요구사항이 계산되면 쿠버네티스는 가장 효율적인 하드웨어 사용을 위해 컨테이너 클러스터 내 컨테이너 실행 위치를 지능적으로 결정할 수 있음
#### 가장 일반적인 런타임 의존성은 **파일 스토리지**
- 쿠버네티스는 컨테이너 재시작에도 삭제되지 않고 유지되는 다용도의 파드 레벨 스토리지로서 볼륨을 제공 (컨테이너 파일 시스템은 일시적이며, 컨테이너가 종료되면 삭제)
- 가장 간단한 볼륨 타입은 `emptyDir`이며, 파드가 살아있는 동안만 존재
- 파드를 다시 시작한 이후에도 볼륨을 유지하려면 다른 ㅈㅇ류의 스토리지 메커니즘을 지원하는 볼륨 필요
  ```yaml
  apiVersion: v1
  kind: Pod
  metadata:
    name: random-generator
  spec:
    containers:
    - image: k8spatterns/random-generator:1.0
      name: random-generator
      volumeMounts:
      - mountPath: "/logs"
        name: log-volume
    volumes:
    - name: log-volume
      persistentVolumeClaim:
        claimName: random-generator-log
  ```
- 스케줄러는 파드가 요청한 볼륨 정보를 판단하고, 이는 파드가 실행될 위치에 영향을 미침
  - 노드가 제공하지 않는 볼륨을 파드가 필요로 하는 경우, 파드는 스케줄링되지 않음
- `hostPath`를 통해 호스트 시스템의 특정 포트로 컨테이너 포트 노출을 요청할 경우, 노드에 또 다른 런타임 의존성이 생성. `hostPort`는 각 노드에 해당 포트의 파드를 하나만 스케줄링되게 제한하므로, 노드 수만큼만 파드 확장 가능

#### 설정(Configuration) 의존성
- 거의 모든 애플리케이션은 설정 정보가 필요한데, 쿠버네티스에서 권장하는 솔루션은 `ConfigMap`
- 애플리케이션 설정에는 **환경 변수**를 이용한 설정, **파일 시스템**을 이용한 설정이 있음
- 요청한 모든 `ConfigMap`이 생성되지 않으면, 컨테이너는 노드에 스케줄링될 수는 있지만 시작되지 않음
```yaml
apiVersion: v1
kind: Pod
metadata:
  name: random-generator
spec:
  containers:
  - image: k8spatterns/random-generator:1.0
    name: random-generator
    env:
    - name: PATTERN  
      valueFrom:
        configMapKeyRef:
          name: random-generator-config  
          key: pattern  
```
- `Secret`도 `ConfigMap`과 비슷한 개념으로, 환경 특화된 설정을 컨테이너에 적용하는 좀 더 안전한 방법을 제공
- 스토리지 및 포트 번호는 클러스터 노드가 제공하지만, `ConfigMap`, `Secret`은 우리가 수행해야하는 단순 관리 작업

### 자원 프로파일 정의
#### 반드시 구별해서 조절해야하는 자원
- 압축 가능 자원: CPU, 네트워크 대역폭저럼 제어 가능한 자원 → 많이 사용할 경우 병목
- 압축 불가능 자원: 메모리처럼 제어 불가능한 자원 → 많이 사용할 경우 컨테이너가 죽어버림(메모리 해제를 요청할 수 있는 방법이 없기 때문)

#### 최소 자원량(requests)과 최대 자원량(limits) 지정
- `requests`는 스케줄러가 파드를 노드에 배치시킬 때 사용됨
   ```yaml
    apiVersion: v1
    kind: Pod
    metadata:
      name: random-generator
    spec:
      containers:
      - image: k8spatterns/random-generator:1.0
        name: random-generator
        resources:
          requests:
            cpu: 100m
            memory: 100Mi
          limits:
            cpu: 200m
            memory: 200Mi
   ```
- 주어진 파드에 대해, 스케줄러는 해당 파드와 파드 안의 모든 컨테이너 요청 자원량을 합산해 충분히 수용할 용량이 있는 노드들만 고려

#### 서비스 품질 (Quality of Service, QoS)
- 최선적(Best-Effort) 파드
  - requests와 limits를 지정하지 않은 경우이며, 가장 낮은 우선순위로 고려
  - 파드가 위치한 노드의 압축 불가능 자원이 전부 사용되어 없어지면 가장 먼저 죽음
- 확장 가능(Burstable) 파드
  - requests와 limits 모두 가지고 있지만 값을 달리 설정한 경우
  - 노드가 압축 불가능 자원에 대한 압박을 받는 경우 이 파드는 최선적 파드가 남아있지 않다면 죽을 확률이 높음
  - 보통 limits는 requests보다 값이 큼
  - 최소한의 자원 보장을 받지만 가능한 경우 limits까지 더 많은 자원을 소비하려고 함
- 보장(Guaranteed) 파드
  - requests와 limits 자원량을 동일하게 갖고 있는 경우
  - 가장 우선순위가 높은 파드이며, 가장 나중에 죽음

### 파드 우선순위 설정
- 파드 우선순위를 사용하면 다른 파드와 비교해 상대적으로 파드의 중요성을 지저할 수 있으며, **파드가 스케줄되는 순서**에 영향을 줌
```yaml
apiVersion: scheduling.k8s.io/v1beta1
kind: PriorityClass
metadata:
  name: high-priority # 우선순위 클래스 객체의 이름
value: 1000  # 객체의 우선순위 값
globalDefault: false
description: This is a very high priority Pod class
---
apiVersion: v1
kind: Pod
metadata:
  name: random-generator
    labels:
      env: random-generator
spec:
  containers:
  - image: k8spatterns/random-generator:1.0
    name: random-generator
  priorityClassName: high-priority # PriorityClass 자원에서 정의된 값으로, 파드에 적용될 우선순위 클래스
```
- 파드를 배치하기에 충분한 용량을 가진 노드가 하나도 없다면, 스케줄러는 자원을 확보하고 우선순위가 높은 파드를 배치하기 위해 노드에서 실행되고 있는 우선순위가 낮은 파드를 제거
- 앞의 파드 서비스 품질(Pod QoS)와 파드 우선순위 기능은 서로 연관되지 않음(서비스 품질은 사용 가능한 컴퓨팅 자원이 낮을 때 노드의 안정성을 유지하기 위해 큐블릿에 의해 주로 사용)
- 큐블릿은 파드를 축출하기 전에 **먼저 서비스 품질을 고려하고, 다음에 파드의 PriorityClass**를 고려
- 스케줄러 축출 로직은 축출 대상을 선택할 때 파드의 서비스 품질을 고려하지 않고, 파드 우선순위를 고려
- 악의적이거나 알 수 없는 사용자가 높은 우선순위를 만들어 그 밖의 모든 파드를 축출하는 경우를 막기 위해, ResourceQuota가 PriorityClass를 지원하도록 확장되었고, 일반적으로 더 큰 우선순위 번호가 예약되어 있음

### 프로젝트 자원 제어
- 공유 멀티테넌트 플랫폼에서의 작업은 특정 경계와 일부 사용자가 플랫폼의 모든 자원을 소비하지 못하게 하는 제어 장치가 있어야 함 
  - `ResourceQuota`: 네임스페이스 내 집계된 자원 소비를 제한하기 위한 제약 조건 제공. 
      → 컴퓨팅 자원 전체 사용량/스토리지 전체 사용량 제한 및 네임스페이스 안에서 생성된 컨피그맵, 시크릿, 파드, 서비스 같은 객체 총 개수 제한
  - `LimitRange`: 각 종류 자원마다 최대 자원량 설정할 수 있음 + `requests`, `limits`의 비율 제어 가능


### 용량 계획
#### 💡 특별한 서비스 요구사항 및 총 서비스 수에 근거해 다양한 환경에 대한 용량 계획을 세우면, 전체 클러스터에 대한 요구사항을 충족하는 비용 효율이 높은 최적의 호스트 프로파일을 만들 수 있음 → 성공적인 클러스터 관리 가능
- 운영 환경이 아닌 개발/스테이지 환경에서 하드웨어를 최적으로 사용하려면 최선적(Best-Effort)과 확장 가능(Burstable) 컨테이너를 주로 사용할 수 있음
  - 이런 동적인 환경에서는 많은 컨테이너가 동시에 시작되고 멈출 수 있음
  - 자원 부족으로 플랫폼이 컨테이너를 죽인다고 하더라도 그다지 치명적이지 않음
- 안정적이고 예측 가능해야 하는 운영 환경에서는 주로 보장(Guaranteed) 컨테이너를 사용하고 약간의 확장 가능 컨테이너를 이용하면 됨
   - 이렇게 설정했음에도 컨테이너가 죽는다면 그것은 클러스터 용량을 확장하라는 신호


## 정리
- 컨테이너는 프로세스 격리뿐만 아니라 패키지 포맷으로서도 유용
- 자원 프로파일이 식별되면, 컨테이너는 성공적인 용량 계획을 위한 구성 요소가 됨
   → 초기 테스트를 수행해 각 컨테이너에 필요한 자원을 찾고 이를 향후 용량 계획 및 용량 예측의 기본정보로 사용
- 자원 프로파일은 스케줄링 및 관리 결정을 돕기 위해 애플리케이션이 쿠버네티스와 통신하는 방법이므로, 모든 애플리케이션에서는 필수로 이와 같은 자원 선언을 염두에 두고 제공해야함
